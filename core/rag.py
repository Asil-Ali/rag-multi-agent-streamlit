import os
import faiss
import pypdf
from sentence_transformers import SentenceTransformer
import streamlit as st

import requests  # Ù„Ùˆ Ø­ØªØ³ØªØ¹Ù…Ù„ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù€ API

# ğŸŒŸ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Streamlit Secrets
api_key = os.getenv("OPENROUTER_API_KEY")

# Ù…Ø«Ø§Ù„: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ headers Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ø¹Ù†Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenRouter
headers = {"Authorization": f"Bearer {api_key}"}

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ­ÙˆÙŠÙ„ embeddings
model = SentenceTransformer("all-MiniLM-L6-v2")
index = faiss.IndexFlatL2(384)  # Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
documents = []

def load_documents(user_files=[]):
    """
    Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª PDF Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© + Ù…Ù„ÙØ§Øª ÙŠØ±ÙØ¹Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    """
    global documents

    # 1ï¸âƒ£ Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ„ PDF ÙÙŠ Ù…Ø¬Ù„Ø¯ data/uploads
    preloaded_path = "data/uploads"
    for filename in os.listdir(preloaded_path):
        if filename.lower().endswith(".pdf"):
            file_path = os.path.join(preloaded_path, filename)
            try:
                with open(file_path, "rb") as f:
                    reader = pypdf.PdfReader(f)
                    text = ""
                    for page in reader.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text
                    if text:
                        documents.append(text)
                        emb = model.encode([text])
                        index.add(emb)
                    else:
                        print(f"Warning: {filename} Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡ØªÙ‡.")
            except Exception as e:
                print(f"Failed to read {filename}: {e}")

    # 2ï¸âƒ£ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª ÙŠØ±ÙØ¹Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø¨Ø± Streamlit
    for file in user_files:
        try:
            reader = pypdf.PdfReader(file)
            text = ""
            for page in reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text
            if text:
                documents.append(text)
                emb = model.encode([text])
                index.add(emb)
        except Exception as e:
            print(f"Failed to read uploaded file {file.name}: {e}")

def search(query, top_k=3):
    """
    Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù€ RAG index
    """
    if not documents:
        return []

    query_emb = model.encode([query])
    D, I = index.search(query_emb, top_k)
    results = [documents[i] for i in I[0] if i < len(documents)]
    return results
